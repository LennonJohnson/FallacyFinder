{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning LLM to detect Fallacies in Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data from:\n",
    "\n",
    "Ruiz-Dolz, R., & Lawrence, J. (2023, December). Detecting Argumentative Fallacies in the Wild: Problems and Limitations of Large Language Models. In M. Alshomary, C.-C. Chen, S. Muresan, J. Park, & J. Romberg (Eds.), Proceedings of the 10th Workshop on Argument Mining (pp. 1–10). Retrieved from https://aclanthology.org/2023.argmining-1.1\n",
    "\n",
    "https://github.com/raruidol/ArgumentMining23-Fallacy/blob/main/README.md\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig, \n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "      with open(\"fallacy_corpus.json\") as filehandle:\n",
    "          json_data = json.load(filehandle)\n",
    "except:\n",
    "      print('The file is not available.')\n",
    "      exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'train': {}, 'dev': {}, 'test': {}}\n",
    "\n",
    "data['train']['label'] = []\n",
    "data['train']['text'] = []\n",
    "data['dev']['label'] = []\n",
    "data['dev']['text'] = []\n",
    "data['test']['label'] = []\n",
    "data['test']['text'] = []\n",
    "\n",
    "fallacyStringConversions = {\n",
    "'None': 0,\n",
    "'AdHominem': 1,\n",
    "'AppealtoEmotion': 2, \n",
    "'AppealtoAuthority': 3, \n",
    "'Slipperyslope': 4,\n",
    "'AppealtoMajority': 5\n",
    "}\n",
    "\n",
    "fallacyNumberConversions = {\n",
    "0: 'None',\n",
    "1: 'AdHominem',\n",
    "2: 'AppealtoEmotion', \n",
    "3: 'AppealtoAuthority', \n",
    "4: 'Slipperyslope',\n",
    "5: 'AppealtoMajority'\n",
    "}\n",
    "\n",
    "for sample in json_data['train']:\n",
    "    data['train']['text'].append(sample[0])\n",
    "    data['train']['label'].append(fallacyStringConversions[sample[1]])\n",
    "\n",
    "for sample in json_data['dev']:\n",
    "        data['dev']['text'].append(sample[0])\n",
    "        data['dev']['label'].append(fallacyStringConversions[sample[1]])\n",
    "\n",
    "for sample in json_data['test']:\n",
    "        data['test']['text'].append(sample[0])\n",
    "        data['test']['label'].append(fallacyStringConversions[sample[1]])\n",
    "\n",
    "\n",
    "final_data = DatasetDict()\n",
    "for k, v in data.items():\n",
    "    final_data[k] = Dataset.from_dict(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "# model_checkpoint = 'roberta-base' # you can alternatively use roberta-base but this model is bigger thus training will take longer\n",
    "\n",
    "\n",
    "# generate classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained( model_checkpoint, num_labels=6, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tokenize function\n",
    "def tokenize_function(examples):\n",
    "    # extract text\n",
    "    text = examples[\"text\"]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2152/2152 [00:00<00:00, 11224.65 examples/s]\n",
      "Map: 100%|██████████| 266/266 [00:00<00:00, 9983.40 examples/s]\n",
      "Map: 100%|██████████| 270/270 [00:00<00:00, 11446.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2152\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 266\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 270\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize training and validation datasets\n",
    "tokenized_dataset = final_data.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 6.76MB/s]\n"
     ]
    }
   ],
   "source": [
    "# import accuracy evaluation metric\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an evaluation function to pass into trainer later\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='SEQ_CLS', inference_mode=False, r=4, target_modules={'q_lin'}, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",\n",
    "                        r=4,\n",
    "                        lora_alpha=32,\n",
    "                        lora_dropout=0.01,\n",
    "                        target_modules = ['q_lin'])\n",
    "peft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 632,070 || all params: 67,590,156 || trainable%: 0.9352\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir= model_checkpoint + \"-lora-text-classification\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creater trainer object\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"dev\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 501/5380 [03:06<54:03,  1.50it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9636, 'grad_norm': 7.326727390289307, 'learning_rate': 0.0009070631970260224, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 538/5380 [03:19<21:35,  3.74it/s]  Trainer is attempting to log a value of \"{'accuracy': 0.6992481203007519}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                  \n",
      " 10%|█         | 538/5380 [03:35<21:35,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8581797480583191, 'eval_accuracy': {'accuracy': 0.6992481203007519}, 'eval_runtime': 16.2397, 'eval_samples_per_second': 16.38, 'eval_steps_per_second': 4.126, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 19%|█▊        | 1001/5380 [05:21<10:01,  7.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7447, 'grad_norm': 2.898487091064453, 'learning_rate': 0.0008141263940520446, 'epoch': 1.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1076/5380 [05:36<13:22,  5.37it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7030075187969925}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 20%|██        | 1076/5380 [05:42<13:22,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.001013159751892, 'eval_accuracy': {'accuracy': 0.7030075187969925}, 'eval_runtime': 5.5637, 'eval_samples_per_second': 47.81, 'eval_steps_per_second': 12.042, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 28%|██▊       | 1501/5380 [07:24<13:13,  4.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5876, 'grad_norm': 4.656132698059082, 'learning_rate': 0.0007211895910780669, 'epoch': 2.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1614/5380 [07:57<21:17,  2.95it/s]  Trainer is attempting to log a value of \"{'accuracy': 0.7142857142857143}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 30%|███       | 1614/5380 [08:04<21:17,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9129266142845154, 'eval_accuracy': {'accuracy': 0.7142857142857143}, 'eval_runtime': 6.5184, 'eval_samples_per_second': 40.808, 'eval_steps_per_second': 10.279, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 37%|███▋      | 2001/5380 [09:31<10:46,  5.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4728, 'grad_norm': 5.205290794372559, 'learning_rate': 0.0006282527881040893, 'epoch': 3.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2152/5380 [10:04<09:44,  5.53it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7255639097744361}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 40%|████      | 2152/5380 [10:10<09:44,  5.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.164086103439331, 'eval_accuracy': {'accuracy': 0.7255639097744361}, 'eval_runtime': 6.413, 'eval_samples_per_second': 41.478, 'eval_steps_per_second': 10.447, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 46%|████▋     | 2501/5380 [11:58<09:03,  5.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4145, 'grad_norm': 69.51883697509766, 'learning_rate': 0.0005353159851301115, 'epoch': 4.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2690/5380 [12:41<08:45,  5.12it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7330827067669173}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 50%|█████     | 2690/5380 [12:47<08:45,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3646290302276611, 'eval_accuracy': {'accuracy': 0.7330827067669173}, 'eval_runtime': 5.4273, 'eval_samples_per_second': 49.011, 'eval_steps_per_second': 12.345, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 56%|█████▌    | 3000/5380 [13:52<10:08,  3.91it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2917, 'grad_norm': 0.1289292275905609, 'learning_rate': 0.00044237918215613383, 'epoch': 5.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 3227/5380 [36:38<06:16,  5.71it/s]     Trainer is attempting to log a value of \"{'accuracy': 0.7556390977443609}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 60%|██████    | 3228/5380 [36:43<06:16,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4447352886199951, 'eval_accuracy': {'accuracy': 0.7556390977443609}, 'eval_runtime': 5.5195, 'eval_samples_per_second': 48.193, 'eval_steps_per_second': 12.139, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/peft/utils/other.py:611: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8404ee94-51f9-4f24-bd56-b30800debec5)') - silently ignoring the lookup for the file config.json in distilbert-base-uncased.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/peft/utils/save_and_load.py:195: UserWarning: Could not find a config file in distilbert-base-uncased - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      " 65%|██████▌   | 3501/5380 [37:59<05:35,  5.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2485, 'grad_norm': 59.20607376098633, 'learning_rate': 0.00034944237918215615, 'epoch': 6.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3766/5380 [39:04<05:34,  4.82it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7330827067669173}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 70%|███████   | 3766/5380 [39:10<05:34,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7574362754821777, 'eval_accuracy': {'accuracy': 0.7330827067669173}, 'eval_runtime': 5.4292, 'eval_samples_per_second': 48.995, 'eval_steps_per_second': 12.341, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 74%|███████▍  | 4001/5380 [40:08<06:26,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1596, 'grad_norm': 21.033737182617188, 'learning_rate': 0.0002565055762081784, 'epoch': 7.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4304/5380 [42:15<04:32,  3.96it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7330827067669173}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 80%|████████  | 4304/5380 [42:35<04:32,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9366859197616577, 'eval_accuracy': {'accuracy': 0.7330827067669173}, 'eval_runtime': 19.2713, 'eval_samples_per_second': 13.803, 'eval_steps_per_second': 3.477, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 84%|████████▎ | 4500/5380 [44:05<05:06,  2.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1468, 'grad_norm': 0.0021800671238452196, 'learning_rate': 0.00016356877323420074, 'epoch': 8.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4842/5380 [45:53<03:54,  2.29it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7368421052631579}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      " 90%|█████████ | 4842/5380 [46:02<03:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0091094970703125, 'eval_accuracy': {'accuracy': 0.7368421052631579}, 'eval_runtime': 8.05, 'eval_samples_per_second': 33.044, 'eval_steps_per_second': 8.323, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      " 93%|█████████▎| 5000/5380 [46:46<01:17,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1128, 'grad_norm': 0.0014380423817783594, 'learning_rate': 7.063197026022306e-05, 'epoch': 9.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5380/5380 [48:22<00:00,  4.68it/s]Trainer is attempting to log a value of \"{'accuracy': 0.7330827067669173}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                   \n",
      "100%|██████████| 5380/5380 [48:36<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0656931400299072, 'eval_accuracy': {'accuracy': 0.7330827067669173}, 'eval_runtime': 13.3405, 'eval_samples_per_second': 19.939, 'eval_steps_per_second': 5.022, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 5380/5380 [48:37<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2917.0913, 'train_samples_per_second': 7.377, 'train_steps_per_second': 1.844, 'train_loss': 0.38968762146052816, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5380, training_loss=0.38968762146052816, metrics={'train_runtime': 2917.0913, 'train_samples_per_second': 7.377, 'train_steps_per_second': 1.844, 'total_flos': 599914265851008.0, 'train_loss': 0.38968762146052816, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions With Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:07<00:00,  9.57it/s]\n",
      "100%|██████████| 68/68 [00:06<00:00, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 0 0 4 0 0 0 0 0 0 0 0 0 4 4 0 4 4 0 0 0 0 0 0 4 0 0 1 3 3 0 3 0 0 3 3 0\n",
      " 0 0 0 3 3 0 0 3 3 0 0 0 3 3 0 3 3 1 3 3 0 0 0 0 0 3 0 4 3 3 0 3 1 5 0 3 0\n",
      " 1 0 3 0 0 0 1 3 0 0 0 0 0 0 5 0 0 0 0 4 0 5 0 0 5 0 5 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 5 3 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 5 0 0 0 0 0 0\n",
      " 0 0 5 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 5 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 3 0 4 0 0 0 4 4 0 4 0 3 0 4 0 0 4 0 4 0 4 3 3 3 3 0 3 4 0 0 0\n",
      " 3 0 0 0 0 3 0 3 3 0 1 0 0 3 3 0 0 0 3 0 3 3 3 0 0 3 5 3 0 0 0 0 0 3 0 0 1\n",
      " 1 3 0 1 3 0 0 3 3 0 3 0 0 0 0 5 5 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 4\n",
      " 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 5 0 5 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 4 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 3 0 0 0 0\n",
      " 3 0 0 0 0 0 5 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dev_predictions = trainer.predict(tokenized_dataset['dev'])\n",
    "dev_predict = np.argmax(dev_predictions.predictions, axis=-1)\n",
    "test_predictions = trainer.predict(tokenized_dataset['test'])\n",
    "test_predict = np.argmax(test_predictions.predictions, axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "# mf1_dev = precision_recall_fscore_support(tokenized_dataset['dev']['label'], dev_predict, average='macro')\n",
    "# mf1_test = precision_recall_fscore_support(tokenized_dataset['test']['label'], test_predict, average='macro')\n",
    "\n",
    "# print('Score in, DEV:', mf1_dev, 'TEST:', mf1_test)\n",
    "# print('Confusion matrix:')\n",
    "# print(confusion_matrix(tokenized_dataset['test']['label'], test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual\t| Predicted\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | None\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "Slipperyslope | Slipperyslope\n",
      "Slipperyslope | None\n",
      "Slipperyslope | None\n",
      "AppealtoAuthority | AdHominem\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AdHominem\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AppealtoAuthority | Slipperyslope\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | AppealtoAuthority\n",
      "AppealtoAuthority | None\n",
      "AdHominem | AppealtoAuthority\n",
      "AdHominem | AdHominem\n",
      "AdHominem | AppealtoMajority\n",
      "AdHominem | None\n",
      "AdHominem | AppealtoAuthority\n",
      "AdHominem | None\n",
      "AdHominem | AdHominem\n",
      "AdHominem | None\n",
      "AdHominem | AppealtoAuthority\n",
      "AdHominem | None\n",
      "AdHominem | None\n",
      "AdHominem | None\n",
      "AdHominem | AdHominem\n",
      "AdHominem | AppealtoAuthority\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | AppealtoMajority\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | Slipperyslope\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | AppealtoMajority\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | AppealtoMajority\n",
      "AppealtoMajority | None\n",
      "AppealtoMajority | AppealtoMajority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoMajority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | Slipperyslope\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoMajority\n",
      "None | AppealtoAuthority\n",
      "None | Slipperyslope\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoAuthority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoMajority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoMajority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoAuthority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | Slipperyslope\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | AppealtoMajority\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "None | None\n",
      "Accuracy: 69.92481203007519\n"
     ]
    }
   ],
   "source": [
    "print(\"Actual\\t| Predicted\")\n",
    "count = 0\n",
    "for i, prediction in enumerate(dev_predict):\n",
    "    if prediction == data['dev']['label'][i]:\n",
    "        count += 1\n",
    "    print(fallacyNumberConversions[data['dev']['label'][i]] + \" | \"+ fallacyNumberConversions[prediction])\n",
    "print(\"Accuracy: \" + str(count/len(dev_predict) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login() # ensure token gives write access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_name = 'lennon2020' \n",
    "model_id = hf_name + \"/\" + \"lora-fallacy-classification\" # you can name the model whatever you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "adapter_model.safetensors: 100%|██████████| 2.53M/2.53M [00:03<00:00, 821kB/s] \n",
      "\n",
      "\u001b[A\n",
      "\n",
      "adapter_model.safetensors:   0%|          | 0.00/2.53M [00:00<?, ?B/s]\n",
      "\n",
      "training_args.bin: 100%|██████████| 5.18k/5.18k [00:00<00:00, 20.5kB/s]30MB/s]\n",
      "events.out.tfevents.1716251357.Lennons-MacBook-Air.local.49143.0: 100%|██████████| 10.2k/10.2k [00:00<00:00, 50.1kB/s]\n",
      "adapter_model.safetensors: 100%|██████████| 2.53M/2.53M [00:03<00:00, 759kB/s] \n",
      "\n",
      "Upload 3 LFS files: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/lennon2020/distilbert-base-uncased-lora-text-classification/commit/98f9ade3b7f9e4024d2ebd9cf70a5eea63d5bbc7', commit_message='lennon2020/lora-fallacy-classification', commit_description='', oid='98f9ade3b7f9e4024d2ebd9cf70a5eea63d5bbc7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(model_id) # save model\n",
    "trainer.push_to_hub(model_id) # save trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
